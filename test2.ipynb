{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.6292603611946106\n",
      "Epoch 2 Loss: 0.6714542433619499\n",
      "Epoch 3 Loss: 0.651294969022274\n",
      "Epoch 4 Loss: 0.6482248455286026\n",
      "Epoch 5 Loss: 0.6146441400051117\n",
      "Epoch 6 Loss: 0.6018929146230221\n",
      "Epoch 7 Loss: 0.5591788403689861\n",
      "Epoch 8 Loss: 0.5747980438172817\n",
      "Epoch 9 Loss: 0.5565221272408962\n",
      "Epoch 10 Loss: 0.5043519921600819\n",
      "Epoch 11 Loss: 0.556438110768795\n",
      "Epoch 12 Loss: 0.4570106025785208\n",
      "Epoch 13 Loss: 0.4779178649187088\n",
      "Epoch 14 Loss: 0.4749242477118969\n",
      "Epoch 15 Loss: 0.5342003963887691\n",
      "Epoch 16 Loss: 0.481483593583107\n",
      "Epoch 17 Loss: 0.44939539581537247\n",
      "Epoch 18 Loss: 0.560304693877697\n",
      "Epoch 19 Loss: 0.572664350271225\n",
      "Epoch 20 Loss: 0.5358593836426735\n",
      "Epoch 21 Loss: 0.48754923790693283\n",
      "Epoch 22 Loss: 0.49835407361388206\n",
      "Epoch 23 Loss: 0.46896854043006897\n",
      "Epoch 24 Loss: 0.42970386520028114\n",
      "Epoch 25 Loss: 0.43588175624608994\n",
      "Epoch 26 Loss: 0.3920796886086464\n",
      "Epoch 27 Loss: 0.4550652429461479\n",
      "Epoch 28 Loss: 0.4064072109758854\n",
      "Epoch 29 Loss: 0.3907865434885025\n",
      "Epoch 30 Loss: 0.4624326266348362\n",
      "Epoch 31 Loss: 0.45040877163410187\n",
      "Epoch 32 Loss: 0.48615406081080437\n",
      "Epoch 33 Loss: 0.44944851100444794\n",
      "Epoch 34 Loss: 0.4064341261982918\n",
      "Epoch 35 Loss: 0.36603268538601696\n",
      "Epoch 36 Loss: 0.4075867086648941\n",
      "Epoch 37 Loss: 0.36714224983006716\n",
      "Epoch 38 Loss: 0.38987915962934494\n",
      "Epoch 39 Loss: 0.4002530463039875\n",
      "Epoch 40 Loss: 0.3446178558515385\n",
      "Epoch 41 Loss: 0.41765812039375305\n",
      "Epoch 42 Loss: 0.3860456943511963\n",
      "Epoch 43 Loss: 0.34487315779551864\n",
      "Epoch 44 Loss: 0.3750209247227758\n",
      "Epoch 45 Loss: 0.40290766954421997\n",
      "Epoch 46 Loss: 0.38751697167754173\n",
      "Epoch 47 Loss: 0.38639908470213413\n",
      "Epoch 48 Loss: 0.42350802570581436\n",
      "Epoch 49 Loss: 0.4086725525557995\n",
      "Epoch 50 Loss: 0.3428550944663584\n",
      "姓名：戴鑫\t预测性别：女\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "# 检查GPU是否可用，如果不可用则使用CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 自定义数据集类\n",
    "class NamesDataset(Dataset):\n",
    "    def __init__(self, names_dict, tokenizer, max_length):\n",
    "        self.names_dict = names_dict\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.names = list(names_dict.keys())\n",
    "        self.labels = [0 if gender == '男' else 1 for gender in names_dict.values()]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name = self.names[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(name, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=self.max_length)\n",
    "        input_ids = encoding['input_ids'].squeeze()\n",
    "        attention_mask = encoding['attention_mask'].squeeze()\n",
    "        return input_ids, attention_mask, label\n",
    "\n",
    "# 加载BERT模型和分词器\n",
    "model_path = 'model'  # 使用预训练的BERT模型\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "bert_model = BertModel.from_pretrained(model_path).to(device)\n",
    "\n",
    "# 定义情感分类模型\n",
    "class SentimentClassification(nn.Module):\n",
    "    def __init__(self, bert_model, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.bert = bert_model\n",
    "        self.fc1 = nn.Linear(bert_model.config.hidden_size, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        x = self.fc1(pooled_output)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 文件路径\n",
    "file_path = 'Chinese_Names_Corpus_Gender（120W）.txt'\n",
    "\n",
    "# 读取文件并存储为字典\n",
    "names_dict = {}\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    sampled_lines = random.sample(lines, len(lines) // 10000)  # 选取1%的数据进行训练\n",
    "    for line in sampled_lines:\n",
    "        name, gender = line.strip().split(',')\n",
    "        names_dict[name.strip()] = gender.strip()\n",
    "\n",
    "# 构建数据集和数据加载器\n",
    "max_length = 10  # 设定最大长度\n",
    "dataset = NamesDataset(names_dict, tokenizer, max_length)\n",
    "train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# 初始化模型、优化器和损失函数\n",
    "output_dim = 2  # 二分类任务\n",
    "hidden_dim = 128  # 隐藏层维度\n",
    "model = SentimentClassification(bert_model, hidden_dim, output_dim).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 训练模型\n",
    "model.train()\n",
    "for epoch in range(50):  # 假设训练5个epoch\n",
    "    total_loss = 0\n",
    "    for input_ids, attention_mask, labels in train_loader:\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} Loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "# 使用模型预测名字对应的性别\n",
    "def predict_gender(model, tokenizer, name):\n",
    "    inputs = tokenizer(name, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=max_length)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items() if key != 'token_type_ids'}  # 将除了token_type_ids之外的所有输入移动到设备上\n",
    "    outputs = model(**inputs)\n",
    "    predicted_class = torch.argmax(outputs, dim=1).item()\n",
    "    gender_label = \"男\" if predicted_class == 0 else \"女\"\n",
    "    return gender_label\n",
    "\n",
    "\n",
    "# 输入自己的名字进行预测\n",
    "your_name = \"戴鑫\"\n",
    "predicted_gender = predict_gender(model, tokenizer, your_name)\n",
    "print(f\"姓名：{your_name}\\t预测性别：{predicted_gender}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dora1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
